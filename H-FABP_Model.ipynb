{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ee74c6-0f80-4be5-af84-04c2b26f22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old model directory deleted (if existed).\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Remove the existing saved_model folder if it exists\n",
    "shutil.rmtree(\"saved_model\", ignore_errors=True)\n",
    "print(\"Old model directory deleted (if existed).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab0a4fc-cd90-4c5d-be03-d558b95dd30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved using TensorFlow's SavedModel API!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple function for the model\n",
    "class SimpleModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = tf.Variable(tf.random.normal([5, 1]), name=\"weight\")\n",
    "        self.b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Save the model using TensorFlow's SavedModel format\n",
    "tf.saved_model.save(model, \"saved_model\")\n",
    "print(\"Model saved using TensorFlow's SavedModel API!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80dbaaaa-e6ae-4549-ab5c-4a6f4bf4c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory exists: True\n",
      "Contents of saved_model: ['assets', 'fingerprint.pb', 'saved_model.pb', 'variables']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Model directory exists:\", os.path.exists(\"saved_model\"))\n",
    "print(\"Contents of saved_model:\", os.listdir(\"saved_model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06195b9b-73b2-4dc5-bf42-463709ec6a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found zero restored functions for caller function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:817\u001b[0m, in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:301\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a restored function or raises an error if no matching function.\"\"\"\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions:\n\u001b[1;32m--> 301\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound zero restored functions for caller function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# This is the format of function.graph.structured_input_signature. At this\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# point, the args and kwargs have already been canonicalized.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (args, kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Found zero restored functions for caller function."
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.saved_model.load(\"saved_model\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Create sample input\n",
    "sample_input = tf.constant(np.random.rand(1, 5), dtype=tf.float32)\n",
    "\n",
    "# Run inference\n",
    "output = loaded_model(sample_input)\n",
    "print(\"Model Output:\", output.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554a0480-f28c-451c-ad2a-cf057d2c676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a signature function for inference\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 5], dtype=tf.float32)])\n",
    "def model_call(x):\n",
    "    return model(x)\n",
    "\n",
    "# Save model with a callable signature\n",
    "tf.saved_model.save(model, \"saved_model\", signatures={\"serving_default\": model_call})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b60194-1fe6-4d01-8e9d-3bb0f1767472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.17678982]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(\"saved_model\")\n",
    "\n",
    "# Get the serving function\n",
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "# Run inference\n",
    "sample_input = tf.constant(np.random.rand(1, 5), dtype=tf.float32)\n",
    "output = infer(x=sample_input)\n",
    "\n",
    "print(\"Model Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb9e41c-3437-448c-8a14-32e517a3f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class SimpleModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = tf.Variable(tf.random.normal([5, 1]), name=\"weight\")\n",
    "        self.b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 5], dtype=tf.float32)])\n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b\n",
    "\n",
    "# Create and save the model\n",
    "model = SimpleModel()\n",
    "tf.saved_model.save(model, \"saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b189d442-f780-4fa4-a348-3ddf5127b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: [[0.07180291]]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.saved_model.load(\"saved_model\")\n",
    "\n",
    "# Create sample input\n",
    "sample_input = tf.constant(tf.random.normal([1, 5]), dtype=tf.float32)\n",
    "\n",
    "# Run inference\n",
    "output = loaded_model(sample_input)\n",
    "print(\"Model Output:\", output.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66493b76-1e63-48ff-afa0-6ce0e9911cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"hfabp_lstm_model\")\n",
    "\n",
    "# Generate synthetic H-FABP data (2 hours, every 15 min)\n",
    "time_intervals = np.arange(0, 2 * 60 + 1, 15)  # Time in minutes\n",
    "np.random.seed(42)\n",
    "hfabp_levels = np.cumsum(np.random.normal(0.1, 0.05, len(time_intervals))) + 2.5\n",
    "\n",
    "# Prepare data for LSTM (reshape into [samples, time_steps, features])\n",
    "X_test = hfabp_levels.reshape((len(hfabp_levels), 1, 1))  # 1 feature, 1 step per sample\n",
    "\n",
    "# Get risk predictions from the model\n",
    "risk_predictions = model.predict(X_test).flatten()  # Flatten to 1D\n",
    "\n",
    "# Define risk thresholds\n",
    "low_risk_threshold = 0.5  # Example threshold (adjust as per model)\n",
    "high_risk_threshold = 0.8\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_intervals, risk_predictions, marker='o', linestyle='-', color='red', label=\"Predicted Risk Level\")\n",
    "\n",
    "# Threshold lines\n",
    "plt.axhline(y=low_risk_threshold, color='green', linestyle='dashed', label=\"Low Risk Threshold\")\n",
    "plt.axhline(y=high_risk_threshold, color='black', linestyle='dashed', label=\"High Risk Threshold\")\n",
    "\n",
    "# Labels & Display\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.ylabel(\"Heart Attack Risk Score\")\n",
    "plt.title(\"Predicted Heart Attack Risk Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94836efb-9133-4f55-80f9-8bda3b3a01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"hfabp_lstm_model\")\n",
    "\n",
    "# Generate synthetic H-FABP data (2 hours, every 15 min)\n",
    "time_intervals = np.arange(0, 2 * 60 + 1, 15)  # Time in minutes\n",
    "np.random.seed(42)\n",
    "hfabp_levels = np.cumsum(np.random.normal(0.1, 0.05, len(time_intervals))) + 2.5\n",
    "\n",
    "# Prepare data for LSTM (reshape into [samples, time_steps, features])\n",
    "X_test = hfabp_levels.reshape((len(hfabp_levels), 1, 1))  # 1 feature, 1 step per sample\n",
    "\n",
    "# Get risk predictions from the model\n",
    "risk_predictions = model.predict(X_test).flatten()  # Flatten to 1D\n",
    "\n",
    "# Define risk thresholds\n",
    "low_risk_threshold = 0.5  # Example threshold (adjust as per model)\n",
    "high_risk_threshold = 0.8\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_intervals, risk_predictions, marker='o', linestyle='-', color='red', label=\"Predicted Risk Level\")\n",
    "\n",
    "# Threshold lines\n",
    "plt.axhline(y=low_risk_threshold, color='green', linestyle='dashed', label=\"Low Risk Threshold\")\n",
    "plt.axhline(y=high_risk_threshold, color='black', linestyle='dashed', label=\"High Risk Threshold\")\n",
    "\n",
    "# Labels & Display\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.ylabel(\"Heart Attack Risk Score\")\n",
    "plt.title(\"Predicted Heart Attack Risk Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc791367-5810-4c0d-b2a0-8b8446b32138",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhfabp_lstm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"hfabp_lstm_model\")\n",
    "\n",
    "# Generate synthetic H-FABP data (2 hours, every 15 min)\n",
    "time_intervals = np.arange(0, 2 * 60 + 1, 15)  # Time in minutes\n",
    "np.random.seed(42)\n",
    "hfabp_levels = np.cumsum(np.random.normal(0.1, 0.05, len(time_intervals))) + 2.5\n",
    "\n",
    "# Prepare data for LSTM (reshape into [samples, time_steps, features])\n",
    "X_test = hfabp_levels.reshape((len(hfabp_levels), 1, 1))  # 1 feature, 1 step per sample\n",
    "\n",
    "# Get risk predictions from the model\n",
    "risk_predictions = model.predict(X_test).flatten()  # Flatten to 1D\n",
    "\n",
    "# Define risk thresholds\n",
    "low_risk_threshold = 0.5  # Example threshold (adjust as per model)\n",
    "high_risk_threshold = 0.8\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_intervals, risk_predictions, marker='o', linestyle='-', color='red', label=\"Predicted Risk Level\")\n",
    "\n",
    "# Threshold lines\n",
    "plt.axhline(y=low_risk_threshold, color='green', linestyle='dashed', label=\"Low Risk Threshold\")\n",
    "plt.axhline(y=high_risk_threshold, color='black', linestyle='dashed', label=\"High Risk Threshold\")\n",
    "\n",
    "# Labels & Display\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.ylabel(\"Heart Attack Risk Score\")\n",
    "plt.title(\"Predicted Heart Attack Risk Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d920d69-2739-4473-b14d-f34e04c6442e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhfabp_lstm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"hfabp_lstm_model\")\n",
    "\n",
    "# Generate synthetic H-FABP data (2 hours, every 15 min)\n",
    "time_intervals = np.arange(0, 2 * 60 + 1, 15)  # Time in minutes\n",
    "np.random.seed(42)\n",
    "hfabp_levels = np.cumsum(np.random.normal(0.1, 0.05, len(time_intervals))) + 2.5\n",
    "\n",
    "# Prepare data for LSTM (reshape into [samples, time_steps, features])\n",
    "X_test = hfabp_levels.reshape((len(hfabp_levels), 1, 1))  # 1 feature, 1 step per sample\n",
    "\n",
    "# Get risk predictions from the model\n",
    "risk_predictions = model.predict(X_test).flatten()  # Flatten to 1D\n",
    "\n",
    "# Define risk thresholds\n",
    "low_risk_threshold = 0.5  # Example threshold (adjust as per model)\n",
    "high_risk_threshold = 0.8\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_intervals, risk_predictions, marker='o', linestyle='-', color='red', label=\"Predicted Risk Level\")\n",
    "\n",
    "# Threshold lines\n",
    "plt.axhline(y=low_risk_threshold, color='green', linestyle='dashed', label=\"Low Risk Threshold\")\n",
    "plt.axhline(y=high_risk_threshold, color='black', linestyle='dashed', label=\"High Risk Threshold\")\n",
    "\n",
    "# Labels & Display\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.ylabel(\"Heart Attack Risk Score\")\n",
    "plt.title(\"Predicted Heart Attack Risk Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea771cf-ea1c-4a47-8459-ba917b2076ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953b29cc-54da-42c5-94b9-cb624f74537e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=hfabp_lstm_model. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(hfabp_lstm_model, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhfabp_lstm_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Generate synthetic H-FABP data (2 hours, every 15 min)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m time_intervals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m15\u001b[39m)  \u001b[38;5;66;03m# Time in minutes\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=hfabp_lstm_model. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(hfabp_lstm_model, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"hfabp_lstm_model\")\n",
    "\n",
    "# Generate synthetic H-FABP data (2 hours, every 15 min)\n",
    "time_intervals = np.arange(0, 2 * 60 + 1, 15)  # Time in minutes\n",
    "np.random.seed(42)\n",
    "hfabp_levels = np.cumsum(np.random.normal(0.1, 0.05, len(time_intervals))) + 2.5\n",
    "\n",
    "# Prepare data for LSTM (reshape into [samples, time_steps, features])\n",
    "X_test = hfabp_levels.reshape((len(hfabp_levels), 1, 1))  # 1 feature, 1 step per sample\n",
    "\n",
    "# Get risk predictions from the model\n",
    "risk_predictions = model.predict(X_test).flatten()  # Flatten to 1D\n",
    "\n",
    "# Define risk thresholds\n",
    "low_risk_threshold = 0.5  # Example threshold (adjust as per model)\n",
    "high_risk_threshold = 0.8\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_intervals, risk_predictions, marker='o', linestyle='-', color='red', label=\"Predicted Risk Level\")\n",
    "\n",
    "# Threshold lines\n",
    "plt.axhline(y=low_risk_threshold, color='green', linestyle='dashed', label=\"Low Risk Threshold\")\n",
    "plt.axhline(y=high_risk_threshold, color='black', linestyle='dashed', label=\"High Risk Threshold\")\n",
    "\n",
    "# Labels & Display\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.ylabel(\"Heart Attack Risk Score\")\n",
    "plt.title(\"Predicted Heart Attack Risk Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb1ed0-d635-41c9-bd57-3c932066c680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
